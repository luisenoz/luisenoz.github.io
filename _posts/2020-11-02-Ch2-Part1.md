> BIG LESSON LEARNED:
Just before starting, let me tell you I lost a complete file with all my notes fron Chapter 2, because I didn't commit the file and closed the page in Github.
So I learnt the hard way that whatever you write or code in **any kind of file doesn't exist in Github until you commit it**, at least for the first time.
_Never leave or close a file/page in Github without commit it, becasue there us no way to recover it!_

# Chapter 2 - From Model to Production

In this chapter, we’re going to use a computer vision example (a bear classifier!!!) to look at the end-to-end process of creating a deep learning application.  
In the process, we’ll discuss:
- the capabilities and constraints of deep learning, 
- explore how to create datasets, 
- look at possible problems when using deep learning in practice, 
- and more.

## The Practice of Deep Learning

Underestimating the constraints and overestimating the capabilities of deep learning may lead to frustratingly poor results.  
Conversely, overestimating the constraints and underestimating the capabilities of deep learning may mean you do not attempt 
a solvable problem because you talk yourself out of it.  
If you keep an open mind and remain open to the possibility that deep learning might solve part of your problem with less data or complexity than you expect, 
you can design a process through which you can find the specific capabilities and constraints related to your particular problem.  

### Starting your project

1. You must have a project to work on.
2. When selecting a project, the most important consideration is data availability.
3. You have to start quickly (*don't wait to have the perfect dataset*).
4. You should iterate from end to end (*don’t spend months fine-tuning your model, or polishing the perfect GUI, or labeling the perfect dataset.
Instead, complete every step as well as you can in a reasonable amount of time, all the way to the end.
5. By using the end-to-end iteration approach, you will also get a better understanding of how much data you really need.
6. it’s probably easiest to get started on a project related to something you are already doing.
7. Maybe you can’t find the exact data you need for the precise project you have in mind; 
but you might be able to find something from a similar domain, or measured in a different way, tackling a slightly different problem.
8. It’s not a good idea to branch out into very different areas, to places that deep learning has not been applied to before. That’s because:
- if your model does not work at first, you will not know whether it is because you have made a mistake, 
or if the very problem you are trying to solve is simply not solvable with deep learning. 
- you won’t know where to look to get help.

In order for us to evaluate if DL would be advatangeous for our project, te authors offer a look at **the state of deep learning**, 
just so we know what kinds of things deep learning is good at right now:

## Computer Vision:
Computers can recognize items in an image at least as well as people can. This is known as *object recognition*.  
DL is also good at recognizing where objects in an image are, and can highlight their locations and name each found object. This is known as *object detection*.  
A variant of this, where every pixel is categorized based on the kind of object it is part of is called *segmentation*.  
However, **DL algorithms are generally not good at recognizing images that are significantly different in structure or style from those used to train the model**.
*(Out-of-Domain data)*.  
Image labeling can be slow and expensive for object detection systems. But One approach that is particularly helpful 
is to synthetically generate variations of input images, such as by rotating them or changing their brightness and contrast; 
this is called **data augmentation** and also works well for text and other types of models.  
Finally, although your problem might not look like a computer vision problem, it might be possible with a little imagination to turn it into one, *(e.g. sounds or tables)*

## Text (Natural Language Processing - NLP)
Computers are good at classifying both short and long documents based on categories.  
Deep learning is also good at generating context-appropriate text.  
However, **DL is not good at generating *correct* responses**. And this is dangerous, because it is so easy to create content 
that appears to a layman to be compelling, but actually is entirely incorrect. And another concern is that context-appropriate, highly compelling responses on social media could be used at massive scale.  
Despite these issues, DL has many applications in NLP: 
- it can be used to translate text from one language to another, 
- summarize long documents into something that can be digested more quickly, 
- find all mentions of a concept of interest, 
- and more.

## Combining Text and Images
The authors generally recommend that DL be used not as an entirely automated process, 
but as part of a process in which the model and a human user interact closely.  
This can potentially make humans orders of magnitude more productive than they would be with entirely manual methods, 
and result in more accurate processes than using a human alone.

## Tabular Data
In this area, DL is generally used as part of an ensemble of multiple types of model.  
If you already have a system that is using random forests or gradient boosting machines, 
then switching to or adding DL may not result in any dramatic improvement.  
DL does greatly increase the variety of columns that you can include and high-cardinality categorical columns.  
On the down side, DL models generally take longer to train than random forests or gradient boosting machines.  

## Recommendation Systems
Recommendation systems are really just a special type of tabular data.  
They generally have a high-cardinality categorical variable representing users, and another one representing products or similar.  
And because DL models are good at handling high-cardinality categorical variables, they are quite good at handling recommendation systems.  
However, nearly all machine learning approaches have the downside that they tell you only which products a particular user might like, 
rather than what recommendations would be helpful for a user.

## Other Data Types
Often you will find that domain-specific data types fit very nicely into existing categories. 
For instance, protein chains look a lot like natural language documents or sounds can be represented as spectrograms.


### The Drivetrain Approach

Many accurate models are of no use to anyone, and many inaccurate models are highly useful.  
To ensure that your modeling work is useful in practice, you need to consider how your work will be used.  
Jeremy offers what he called **The Drivetrain Approach** to help us thinking about this issue.  
The approach was described in detail in “Designing Great Data Products”, <https://www.oreilly.com/radar/drivetrain-approach-data-products/>. 





