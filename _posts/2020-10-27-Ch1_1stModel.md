# CHAPTER 1.2: MY FIRST MODEL!!!

The authors aim is to teach us how to do things before they explain why they work. 
With this top-down approach, we will begin by actually training an image classifier to recognize dogs and cats.

## THE SETUP

**A GPU (Graphic Processing Unit) Deep Learning Server**

To do most of the works in the book, (and apparently for any serious incursion into any DL project) we’ll need access to a computer with an NVIDIA GPU.

Setting up a computer takes time and energy, and as we want all our energy focused on deep learning; the authors strongly suggest we to rent access to a computer
that already has everything we'll need preinstalled and ready to go.
The book website suggest a few options: Google Colab, PaperspaceGradient and Sagemaker

I chose Gradient, because it provides acces to a Jupyter Notebook instance backed by a free GPU without any complicated installs or configuration. 
Gradient is built on top of Paperspace, a GPU-accelerated cloud platform, and recently introduced free GPU and CPU instances. 
To use them, choose Free-GPU or Free-P5000 (recommended) when creating the Notebook.

The book site includes a reasonable guide to get connected and star working on a notebook, but, at least for me, it's not so quick and straight forward as they say.
And once you start working, the process of stop and most importantly start the notebook is longer than what I expected. But it's still such a small price to pay!
The most important things to take into account when creating the notebook were:
- Choose fast.ai as the container. *(there are others like TensorFlow, Rapids or even PyTorch)*
- Choose one of the free GPU machines *(preferably the P5000 if available)*
- **Update the fastai library**
- Stop your notebook every time you finish working on it, particularly is you selected a paid instance.

One very important consideration is to **keep your files in the /storage folder!!!**
Otherwise, the changes you make to the notebooks are not going to be saved when you logout.

Following is one way to do it in Gradient:
1. The fastbook folder contains a folder called “clean”, where you will find all the notebooks from fastbook.
2. Copy that folder to /storage in order to maintain any changes that you make to these files.
3. To make the copy, in the notebook top right corner click the NEW botom and select Terminal to open one.
4. In the terminal enter the following code:

    '''mkdir /storage/mynotebooks

    cp /fastbook/clean/* /storage/mynotebooks/'''

5. That will create a directory called mynotebboks in the /storage folder with a fresh copy of all notebboks and other files needed.
6. Those are the notebooks where you should work and experiment

## RUNNIING MY FIRST MODEL (in a Notebook)

The notebooks are numbered by chapter in the same order as in the book.
So I started by opening the "Lesson 1_Your first model" notebook
Once in the notebook, I just followed the concepts in the book and run each cell also following the steps in the book.  
As someone that had never seem fastai before, the code was not easy to decipher (and it is not the intention at this stage),
but I could at least  understand the tasks involved in each step, mostly thanks to my previous readings about neural networks 
and some brief experience with Keras (another DL library based on TensorFlow).

As a suumary, following are the main steps I followed to run my first model:

1. Download a dataset of dogs and cats photos, (the dataset is already part of the fastai library datasets).
2. Get a *pretrained model* that already learned from similar datasets with huge volumes of data.
3. Fine tune the model to adapt it to the new dataset.
And that is it!!! 
- Eight lines of code 
- Run for about 30 seconds
- And the model was trained to recognise a cat or a dog with 99.5% accuracy!!!

I even tried with other photos from the internet or from my own photo albums, and the predictions were always right.  
I started to uderstand the details and the importance of the pretrained model later in the course, but that fisrt run was close to magical.

The model in the notebook was designed to identify cats:

       'def is_cat(x): return x[0].isupper()
        dls = ImageDataLoaders.from_name_func(
            path, get_image_files(path), valid_pct=0.2, seed=42,
            label_func=is_cat, item_tfms=Resize(224))

        learn = cnn_learner(dls, resnet34, metrics=error_rate)
        learn.fine_tune(1)'

So I decided to create one for dogs.  
It was so easy as to copy and paste the cat predictor, change a couple of values, and voila!.

       'def is_dog(x): return x[0].islower()
        dls = ImageDataLoaders.from_name_func(
            path, get_image_files(path), valid_pct=0.2, seed=42,
            label_func=is_dog, item_tfms=Resize(224))

        learn = cnn_learner(dls, resnet34, metrics=error_rate)
        learn.fine_tune(1)'

My dog predictor worked with the same efficiency than the original for cats.

**The magic was gone to make place for a bit more understanding.**




