# CHAPTER 5.1: IMAGE CLASSIFICATION

To make your model really work, and work reliably, there are a lot of details you have to get right, 
and a lot of details that you have to check.     
This process requires being able to look inside your neural network as it trains and as it makes predictions, 
find possible problems, and know how to fix them.

We'll need to do a deep dive into the mechanics of deep learning. 
- What is the architecture of a computer vision model, 
 - an NLP model, 
 - a tabular model, and others.
 - How do we create an architecture that matches the needs of our particular domain
 - How do we get the best possible results from the training process 
 - How do we make things faster
 - What do we have to change as our datasets change.
 
 We will start by repeating the same basic applications that we looked at in the first chapter, but we are going to do two things: 
 - Make them better.  
 - Apply them to a wider variety of types of data.

## FROM DOGS AND CATS TO PET BREEDES

The same dataset we used to identify cats from dogs will also allow us to work on a much more challenging problem:     
**figuring out what breed of pet is shown in each image.**

In real life, we'll normally start with a dataset that we don't know anything about. We then have to figure out:
= how it is put together, 
- how to extract the data we need from it, 
- and what that data looks like.

We already downloaded the Pets dataset, and we can get a path to this dataset using the same code as in Chapter 1: 
```python
from fastai.vision.all import *
path = untar_data(URLs.PETS)
```

Now, to be able to extract the breed of each pet, we'll need to understand how the data is laid out.     
Data is usually provided in one of these two ways: 
- Individual files representing items of data, possibly organized into folders or with filenames representing information about those items  
- A table of data (e.g., in CSV format) in which each row is an item and may include filenames providing connections between the data in the table 
and data in other formats, such as text documents and images.

To see what is in our dataset, we can use the *ls* method: 
```python
path.ls() 
```
(#3) [Path('annotations'),Path('images'),Path('models')]

The *annotations* directory contains information about where the pets are. 
Since we'll be doing classification, not localization, we will ignore the *annotations* directory.     
We can use the same *ls* method to se what's inside the *images* folder:
```python
(path/'images').ls()
```

(#7394) [Path('images/great_pyrenees_173.jpg'),Path('images/wheaten_terrier_46.jpg'),
Path('images/Ragdoll_262.jpg'),Path('images/german_shorthaired_3.jpg'),
Path('images/american_bulldog_196.jpg'),Path('images/boxer_188.jpg'),
Path('images/staffordshire_bull_terrier_173.jpg'),Path('images/basset_hound_71.jpg'),
Path('images/staffordshire_bull_terrier_37.jpg'),Path('images/yorkshire_terrier_18.jpg')...].    

The first thing that is shown is the number of items in the collection, prefixed with a *#*, and only the first few items are displayed.

We can see that each file name is structured as follows:
1. the pet breed,
2. then an underscore (_),
3. a number,
4. the file extension (.jpg)

We need to create a piece of code that extracts the breed from a single Path, and the use it for the whole dataset.     
To allow us to test our code, let’s pick out one of these filenames: 
```python
fname = (path/"images").ls()[0]
```
The authors suggest that the most powerful and flexible way to extract information from strings like this is to use a **regular expressions**, 
also known as a ***regex***. A regular expression is a special string, written in the regular expression language, 
which specifies a general rule for deciding whether another string passes a test (i.e., “matches” the regular expression), 
and also possibly for plucking a particular part or parts out of that other string.

> Since Jeremy talks so highly about *regex* and considers them as one of the most useful tools in our programming toolkit, and also many of his students found regex as the most exiting tool to learn, I dived into several tutorials in the web and summarised the main concpets in a notebook. I hadn't worked with regex before and found them interesting but challenging and not easy to digest without a lot of prectice. But you can form your opinion looking at the notebook here, if you're not used to them. [regex notebook](https://github.com/luisenoz/luisenoz.github.io/blob/master/images/RegEx.ipynb)

Jeremy uses *findall*, one of the *regex* methods, to try a regular expression against the filename of the *fname* object:
```python
re.findall(r'(.+)_\d+.jpg$', fname.name)
```
*This regular expression plucks out all the characters leading up to the last underscore character, 
as long as the subsequent characters are numerical digits and then the JPEG file extension.*

['great_pyrenees']

Now that we know it worked for one example, we ca use it to label the whole dataset.     
As expected, *fastai* comes with several classes to help with labelling. For example, if we want to label with regular expressions, we can use the *RegexLabeller* class. And in this case we'll use the Datablock API we already used in Chapter 2.
```python
pets = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files,
splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),
                 batch_tfms=aug_transforms(size=224, min_scale=0.75))
dls = pets.dataloaders(path/"images")
```
One important piece of this DataBlock call that we haven’t seen before is in these two lines: 
```python
item_tfms=Resize(460),
batch_tfms=aug_transforms(size=224, min_scale=0.75)
```

Those lines implement a *fastai* data augmentation strategy called *presizing*, that is designaed to reduce data destruction while maintaining a good performance.

## Presizing

We need the images to have all the same dimensions.     
We also search to minimise the claculations needed for augmentation.     
There is also the challenge that, if performed after resizing down, various common data augmentation transforms might introduce 
spurious empty zones, degrade data, or both.
*Presizing* adopts two startegies to work around those challenges:
1. Resizes images to relatively *large* dimensions - significantly larger than the target training dimensiosn.
2. Compose all common augmentation operations *(including a resize to the final target size)* into one, 
and perform the combined operation on the GPU only once at the end of processing, 
rather than performing the operations individually and interpolating multiple times.

The first step, ***crop full width or height*** is in *item_tfms* so it's applied to each individual image before it's copied to the GPU. It ensures all images are of the same size.     
The resize, creates images large enough that they have spare margin to allow further augmentation transforms on their inner regions without creating empty zones. This transformation works by resizing to a square, using a large crop size. On the training set, the crop area is chosen randomly, and the size of the crop is selected to cover the entire width (for portrait images) or height (for landscape images) of the image, whichever is smaller. In the validation set the centre square of the image is always chosen.

In the second step, ***random crop and augment*** is in *batch_tfms* and it's applied to a batch all at once on the GPU, which means is faster and all of the potentially destructive operations are done together, with a single interpolation at the end. On the validation set, only the resize to the final size needed for the model is done here. On the training set, the random crop and any other augmentations are done first.

To implement this process in fastai, you use *Resize* as an item transform with a large size, and *RandomResizedCrop* as a batch transform with a smaller size. *RandomResizedCrop* will be added if you include the *min_scale* parameter in your *aug_transforms* function, as was done in the DataBlock. Alternatively, you can use *pad* or *squish* instead of *crop* (the default) for the initial *Resize*.

If you looked at an image that has been zoomed, interpolated, rotated, and then interpolated again *(which is the approach used by all other deep learning libraries)*, and an image that has been zoomed and rotated as one operation and then interpolated once *(the fastai approach)*, you would see that the first image is less well defined and could have reflection padding artifacts; as well as some parts disappeared entirely. Jeremy found that, in practice, using *presizing* significantly improves the accuracy of models and often results in speedups too.

### Checking and debugging a DataBlock

Writing a DataBlock we will get an error message if we have a syntax error somewhere in our code, but we have no guarantee that our template is going to work on our data source as we intend. So, **before training a model, we should always check our data**.

```python
dls.show_batch(nrows=1, ncols=3)
```
The *show_batch* method will show the images and we can then check that each photo corresponds to the right label. If we're not familiar with the dataset, we can always search a sample in Google and verify that our images and labels are right.

If we made a mistake while building our DataBlock, we likely won’t see it before this step.     
To debug this, the authors encourage us to use the *summary* method. It will attempt to create a batch from the source we give it, with a lot of details.     
Also, if it fails, we will see exactly at which point the error happens, and the library will try to give some help.

For instance, one common mistake is to forget to use a *Resize* transform, so we end up with pictures of different sizes and are not able to batch them.

```python
pets1 = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files, 
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'))
pets1.summary(path/"images")
```
The summary will provide the following result:

---
Setting-up type transforms pipelines.    
Collecting items from /storage/data/oxford-iiit-pet/images.    
Found 7390 items.    
2 datasets of sizes 5912,1478.    
Setting up Pipeline: PILBase.create.    
Setting up Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}.    

Building one sample.    
  Pipeline: PILBase.create.    
      starting from.    
            /storage/data/oxford-iiit-pet/images/shiba_inu_98.jpg.    
      applying PILBase.create gives.    
      PILImage mode=RGB size=500x374
      Pipeline: partial -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}.    
      starting from.    
           /storage/data/oxford-iiit-pet/images/shiba_inu_98.jpg.    
      applying partial gives. 
      shiba_inu.    
      applying Categorize -- {'vocab': None, 'sort': True, 'add_na': False} gives.    
      TensorCategory(33)

Final sample: (PILImage mode=RGB size=500x374, TensorCategory(33))

Setting up after_item: Pipeline: ToTensor.    
Setting up before_batch: Pipeline:      
Setting up after_batch: Pipeline: IntToFloatTensor -- {'div': 255.0, 'div_mask': 1}

Building one batch.    
Applying item_tfms to the first sample:     
  Pipeline: ToTensor.    
      starting from.    
       (PILImage mode=RGB size=500x374, TensorCategory(33))
    applying ToTensor gives.    
     (TensorImage of size 3x374x500, TensorCategory(33))

Adding the next 3 samples

No before_batch transform to apply

Collating items in a batch.     
**Error! It's not possible to collate your items in a batch. 
Collating items in a batch.     
Could not collate the 0-th members of your tuples because got the following shapes.     
torch.Size([3, 374, 500]),torch.Size([3, 375, 500]),torch.Size([3, 500, 424]),torch.Size([3, 351, 500])**

---

We can see exactly how we gathered the data and split it, how we went from a filename to a sample (the tuple (image, category)), 
then what item transforms were applied and how it failed to collate those samples in a batch (because of the different shapes).

Once we think the data looks right, the authors generally recommend the next step should be using it to train a simple model.     
For this initial test, we can use the same simple model that we used in Chapter 1:
```python
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(2)
```
|epoch. |train_loss. |valid_loss  |error_rate  |time|
|-----|-----|-----|-----|-----|
|0	|1.483786	|0.346272	|0.100812	|00:30|

|epoch. |train_loss. |valid_loss  |error_rate  |time|
|-----|-----|-----|-----|-----|
|0	|0.495099	|0.311673	|0.089986	|00:35|
|1	|0.318182	|0.216932	|0.071719	|00:30|

We haven’t actually told fastai what loss function we want to use. But fastai will generally try to select an appropriate loss function 
based on the kind of data and model we are using.     
In this case, we have image data and a categorical outcome, so fastai will default to using ***cross-entropy loss***.


## Cross-Entropy Loss

Cross-entropy loss is a function similar to the one we've been using but with 2 advantages:
1. It works, even when the dependent variable has more than 2 categories *(several breeds instead of dog or cat)*
2. It results in faster and more reliable training.

But, before trying to understand how cross-entropy loss works, we first have to understand how the actual data 
and activations that are seen by the loss function look like.

### Viewing Activation and Labels

We can start by using the *one_batch* method to get a btach of real data from the *DataLoaders*
```python
x,y = dls.one_batch()
y
```
TensorCategory([31,  4,  1, 30,  6,  6, 11, 15, 24, 14, 13, 17,  2, 12,  5, 34,  6, 19, 15,  3,  7,  8, 33, 12,  8,     
1, 13, 14, 30,  8, 25, 32, 25,  5, 17, 31, 29,  9, 35, 24,  2, 30, 15, 19,  6, 35, 10,  5,     
        14,  6, 10, 29, 25, 22,  2, 33,  6,  7, 25, 29, 27, 15, 32, 13], device='cuda:0')

Our batch size is 64, so we have 64 rows in this tensor.     
Each row is a single integer between 0 and 36, representing our 37 possible pet breeds.

We can view the predictions *(the activations of the final layer of our neural network)* by using *Learner.get_preds*.     
This function takes either a dataset index (0 for train and 1 for valid) or an iterator of batches. Thus, we can pass it a simple list with our batch to get our predictions.     
It returns predictions and targets by default, but since we already have the targets, we can effectively ignore them by assigning to the special variable *_*:

```python
preds,_ = learn.get_preds(dl=[(x,y)])
preds[0]
```
TensorImage([2.9641e-08, 5.0075e-07, 8.4463e-07, 9.4931e-07, 4.5364e-06, 1.2933e-05, 1.2391e-06, 3.8727e-05, 1.4260e-05, 1.2109e-06, 4.3693e-08, 2.6370e-07, 3.9565e-06, 6.5704e-06, 1.8649e-06, 1.2336e-06,
        1.7263e-07, 1.7804e-07, 4.4786e-07, 1.1471e-05, 2.4972e-06, 1.7159e-03, 3.1686e-04, 3.8349e-06, 2.3981e-04, 2.3053e-06, 3.4829e-07, 1.0206e-04, 2.3513e-05, 8.6500e-08, 4.5018e-06, 9.9747e-01,
        1.9257e-06, 1.3839e-06, 1.1302e-05, 2.8269e-06, 4.5107e-07])
        
The predictions are 37 probabilities that go from 0 to 1, and total 1.
```python
len(preds[0]),preds[0].sum()
```
(37, TensorImage(1.))

To transform the activations of our model into predictions like this, we used a new fucntion called the ***softmax*** **activation function**.

### Softmax

We used the *softmax* function in the last layer of the model to ensure that the activations were all between 0 and 1, and that all they sum to 1.     
softmax is the multi-category equivalent of sigmoid — we have to **use it anytime we have more than two categories** and the probabilities of the categories must add to 1, and we often use it even when there are just two categories, just to make things a bit more consistent.     
```python
def softmax(x): 
     return exp(x) / exp(x).sum(dim=1, keepdim=True)
```

```python
torch.random.manual_seed(42);
acts = torch.randn((6,2))*2
acts
```
tensor([[ 0.6734,  0.2576],     
        [ 0.4689,  0.4607],     
        [-2.2457, -0.3727],     
        [ 4.4164, -1.2760],     
        [ 0.9233,  0.5347],     
        [ 1.0698,  1.6187]])

```python
sm_acts = torch.softmax(acts, dim=1)
sm_acts
```
tensor([[0.6025, 0.3975],     
        [0.5021, 0.4979],     
        [0.1332, 0.8668],     
        [0.9966, 0.0034],     
        [0.5959, 0.4041],     
        [0.3661, 0.6339]])
        

> **Jargon:** Exponential Function (exp) Defined as e ** x, where e is a special number approximately equal to 2.718. 
It is the inverse of the natural logarithm function. Note that **exp is always positive and increases very rapidly!**

Taking the exponential ensures all our numbers are positive, and then dividing by the sum ensures we are going to have a bunch of numbers that add up to 1.     
The exponential also has a nice property: if one of the numbers in our activations x is slightly bigger than the others, the exponential will amplify this (since it grows exponentially), which means that in the *softmax*, that number will be closer to 1. So it’s ideal for training a classifier when we know each picture has a definite label.     
*(Note that it may be less ideal during inference, as you might want your model to sometimes tell you it doesn’t recognize any of the classes that it has seen during training, and not pick a class because it has a slightly bigger activation score.)*

*Softmax* is the first part of the cross-entropy loss — the second part is *log likelihood*.

### Log Likehood

As we moved from *sigmoid* to *softmax*, we need to extend the loss function to work with any number of categories *(in this case, we have 37 categories)*.     
Our activations, after softmax now, are between 0 and 1, and sum to 1 for each row in the batch of predictions.     
Our targets are integers between 0 and 36.

In the binary case, we used *torch.where* to select between *inputs* and *1-inputs*.
```python
def mnist_loss(inputs, targets):
    inputs = inputs.sigmoid()
    return torch.where(targets==1, 1-inputs, inputs).mean()
```
But when we take a binary classification just as another type of a general classifiaction but with only 2 categories, it becomes easier, 
because we now have 2 columns containing the equivalent of *inputs* and *1-inputs*, and so, all we need to do is select the value from the right column.     
Let's look at how it would work in Pytorch, with an example based on 3s and 7s:
1. Let's say these are our labels:
```python
targ = tensor([0,1,0,1,1,0])
```
2. And these the *softmax* activation *(from the previus run)*:
```python
sm_acts
```
tensor([[0.6025, 0.3975],     
        [0.5021, 0.4979],     
        [0.1332, 0.8668],     
        [0.9966, 0.0034],     
        [0.5959, 0.4041],     
        [0.3661, 0.6339]])
        
Then for each item of *targ*, we can use that to select the appropriate column of *sm_acts* using **tensor indexing**:
```python
idx = range(6)
sm_acts[idx, targ]
```
tensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661])

To see what’s happening here, let’s put all the columns together in a table, where the first two columns are our activations, then we have the targets, the row index, and finally the result shown in the preceding code:
```python
from IPython.display import HTML
df = pd.DataFrame(sm_acts, columns=["3","7"])
df['targ'] = targ
df['idx'] = idx
df['loss'] = sm_acts[range(6), targ]
t = df.style.hide_index()
#To have html code compatible with our script
html = t._repr_html_().split('</style>')[1]
html = re.sub(r'<table id="([^"]+)"\s*>', r'<table >', html)
display(HTML(html))
```
|3	|7	|targ	|idx	|loss  |
|:---|:---|:---|:---|:---|
|0.602469	|0.397531	|0	|0	|0.602469|
|0.502065	|0.497935	|1	|1	|0.497935|
|0.133188	|0.866811	|0	|2	|0.133188|
|0.996640	|0.003360	|1	|3	|0.003360|
|0.595949	|0.404051	|1	|4	|0.404051|
|0.366118	|0.633882	|0	|5	|0.366118|

From the table, we can see that the final column ("loss") can be calculated by taking the *targ* and *idx* columns as indices into the two-column matrix containing the 3 and 7 columns.     
That’s what ```sm_acts[idx, targ]``` is doing:

- sm_acts[0][0] = 0.602469
- sm_acts[1][1] = 0.497935
- ...
- sm_acts[5][0] = 0.366118

This works just as well with more than two columns. If we added an activation column for every digit (0 through 9), and then *targ* contained a number from 0 to 9, as long as the activation columns sum to 1 (as they will, if we use softmax), we’ll have a loss function that shows how well we’re predicting each digit.

We’re picking the loss only from the column containing the correct label. We don’t need to consider the other columns, because by the definition of softmax, they add up to 1 minus the activation corresponding to the correct label. Therefore, making the activation for the correct label as high as possible we're also decreasing the activation of the remaining columns.

As usual, PyTorch provides a function that does exactly the same thing as *sm_acts[range(n), targ]* *(except it takes the negative, because when applying the log afterward, we will have negative numbers)*, called **nll_loss** *(NLL stands for negative log likelihood)*:

```python
sm_acts[idx, targ]
```
tensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661])

```python
F.nll_loss(sm_acts, targ, reduction='none')
```
tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])

However, despite its name, this *nll_loss* function doesn't take the log.

### Taking the log

The function we saw in the previous section works quite well as a loss function, but the problem is that we are using probabilities, 
and probabilities cannot be smaller than 0 or greater than 1. That means our model will not care whether it predicts 0.99 or 0.999. 
While those numbers are very close together — in another sense, 0.999 is 10 times more confident than 0.99.

So, to solve that limiation we want to transform our numbers between 0 and 1 to instead be between negative infinity and infinity.   
And there is a mathematical function that does exactly this: **the logarithm** (available as ***torch.log***).   
The logarithm function has this identity: 
y = b ** a.  
a = log(y,b).     
A quantity representing the power *(a)* to which a fixed number (the base) *(b)* must be raised to produce a given number *(y)*.
In this case, we’re assuming that log(y,b) returns log y base b. However, *log* in Python uses the special number *e* (2.718…) as the base.   
n = log (y, e) = The power *n* to which *e* must be raised to produce *y*.   

The key thing to know about logarithms for DL is this relationship:  

**log(a*b) = log(a)+log(b)**     

It means that logarithms increase linearly when the underlying signal increases exponentially or multiplicatively.     
The clear advantage is that multiplication, which can create really, really large and really, really small numbers, 
can be replaced by addition, which is much less likely to result in scales that are difficult for our computers to handle.

Taking the mean of the positive or negative log of our probabilities (depending on whether it’s the correct or incorrect class) 
gives us the negative log likelihood loss. In PyTorch, *nll_loss* assumes that you already took the log of the softmax, 
so it doesn’t do the logarithm for you.

> The “nll” in *nll_loss* stands for “negative log likelihood,” but it doesn’t actually take the log at all! 
It assumes you have already taken the log.    
PyTorch has a function called *log_softmax* that combines log and softmax in a fast and accurate way, 
but *nll_loss* is designed to be used after log_softmax.

When we first take the *softmax*, and then the *log likelihood* of that, that combination is called ***cross-entropy loss***. 
In PyTorch, this is available as ***nn.CrossEntropyLoss*** (which, in practice, does *log_softmax* and then *nll_loss*):
```python
loss_func = nn.CrossEntropyLoss()
'''
This is a class. Instantiating it gives an object that behaves like a function:
```python
loss_func(acts, targ)
```
tensor(1.8045)

All PyTorch loss functions are provided in two forms, the class form just shown as well as a plain functional form, available in the F namespace: 
```python
F.cross_entropy(acts, targ)
```
tensor(1.8045)

By default, PyTorch loss functions take the mean of the loss of all items, but we can use *reduction='none'* to disable that:
```python
nn.CrossEntropyLoss(reduction='none')(acts, targ)
```
tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])

## Model Interpretation

It’s very hard to interpret loss functions directly, because they are designed to be things computers can differentiate and optimize, 
not things that people can understand.     
That’s why we have metrics. These are not used in the optimization process, but just to help us understand what’s going on.     
We saw in Chapter 1 that we can use a *confusion matrix* to see where our model is doing well and where it’s doing badly:
```python
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix(figsize=(12,12), dpi=60)
```
This confusion matrix is very hard to read. We have 37 pet breeds, which means we have 37×37 entries in this giant matrix!     
Instead, we can use the *most_confused method*, which just shows us the cells of the confusion matrix with the most incorrect predictions (here, with at least 5 or more):
```python
interp.most_confused(min_val=5)
```
[('Ragdoll', 'Birman', 8),     
 ('miniature_pinscher', 'chihuahua', 8),     
  ('staffordshire_bull_terrier', 'american_pit_bull_terrier', 5)]
  
A little bit of Googling tells us that the most common category errors shown here are breed differences that even expert breeders sometimes disagree about.     
So, we seem to have a good baseline. What can we do now to make it even better?

## Improving the model






